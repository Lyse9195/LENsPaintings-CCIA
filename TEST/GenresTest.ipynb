{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237873a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import sympy\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "import torch_explain as te\n",
    "from torch_explain.nn.functional import entropy_logic_loss\n",
    "from torch_explain.logic.nn import entropy\n",
    "from torch_explain.nn import concepts\n",
    "from torch_explain.logic.metrics import test_explanation, complexity\n",
    "from natsort import natsorted, index_natsorted\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ed1c8",
   "metadata": {},
   "source": [
    "# **Data preprocessing**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03ebafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../DATA/GenresQArtDataset.csv\", sep=';', on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0e5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'genre painting': 'genre_painting'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df['people_no'] = ((df['people'] == \"0\")).astype(int)\n",
    "df['people_few'] = ((df['people'] == \"0,33\")).astype(int)\n",
    "df['people_group'] = ((df['people'] == \"0,66\")).astype(int)\n",
    "df['people_lot'] = (df['people'] == \"1\").astype(int)\n",
    "\n",
    "df.drop(columns=['people'], inplace=True)\n",
    "\n",
    "df['trees_no'] = (df['trees'] == \"0\").astype(int)\n",
    "df['trees_few'] = (df['trees'] == \"0,5\").astype(int)\n",
    "df['trees_lot'] = (df['trees'] == \"1\").astype(int)\n",
    "\n",
    "df.drop(columns=['trees'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2002a55",
   "metadata": {},
   "source": [
    "# **LEN work**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29743d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 1 Test Loss: 0.1520\n",
      "Fold 1 Precision: 0.8750\n",
      "Fold 1 Accuracy: 0.6842\n",
      "Fold 1 history Accuracy: 0.8421\n",
      "Fold 1 history Complexity: 15.0000\n",
      "Fold 1 landscape Accuracy: 0.9474\n",
      "Fold 1 landscape Complexity: 4.0000\n",
      "Fold 1 portrait Accuracy: 0.8947\n",
      "Fold 1 portrait Complexity: 7.0000\n",
      "Fold 1 genre Accuracy: 0.7368\n",
      "Fold 1 genre Complexity: 5.0000\n",
      "Fold 1 stilllife Accuracy: 1.0000\n",
      "Fold 1 stilllife Complexity: 4.0000\n",
      "Fold 2\n",
      "Fold 2 Test Loss: 0.4362\n",
      "Fold 2 Precision: 0.7059\n",
      "Fold 2 Accuracy: 0.6667\n",
      "Fold 2 history Accuracy: 0.7778\n",
      "Fold 2 history Complexity: 6.0000\n",
      "Fold 2 landscape Accuracy: 0.7778\n",
      "Fold 2 landscape Complexity: 5.0000\n",
      "Fold 2 portrait Accuracy: 0.9444\n",
      "Fold 2 portrait Complexity: 6.0000\n",
      "Fold 2 genre Accuracy: 0.7778\n",
      "Fold 2 genre Complexity: 13.0000\n",
      "Fold 2 stilllife Accuracy: 1.0000\n",
      "Fold 2 stilllife Complexity: 2.0000\n",
      "Fold 3\n",
      "Fold 3 Test Loss: 0.2903\n",
      "Fold 3 Precision: 0.7273\n",
      "Fold 3 Accuracy: 0.4444\n",
      "Fold 3 history Accuracy: 0.8333\n",
      "Fold 3 history Complexity: 9.0000\n",
      "Fold 3 landscape Accuracy: 0.8333\n",
      "Fold 3 landscape Complexity: 3.0000\n",
      "Fold 3 portrait Accuracy: 0.8333\n",
      "Fold 3 portrait Complexity: 3.0000\n",
      "Fold 3 genre Accuracy: 0.7222\n",
      "Fold 3 genre Complexity: 2.0000\n",
      "Fold 3 stilllife Accuracy: 1.0000\n",
      "Fold 3 stilllife Complexity: 2.0000\n",
      "Fold 4\n",
      "Fold 4 Test Loss: 0.2319\n",
      "Fold 4 Precision: 0.9231\n",
      "Fold 4 Accuracy: 0.6667\n",
      "Fold 4 history Accuracy: 0.8889\n",
      "Fold 4 history Complexity: 10.0000\n",
      "Fold 4 landscape Accuracy: 0.8889\n",
      "Fold 4 landscape Complexity: 8.0000\n",
      "Fold 4 portrait Accuracy: 0.9444\n",
      "Fold 4 portrait Complexity: 4.0000\n",
      "Fold 4 genre Accuracy: 0.8333\n",
      "Fold 4 genre Complexity: 12.0000\n",
      "Fold 4 stilllife Accuracy: 0.9444\n",
      "Fold 4 stilllife Complexity: 5.0000\n",
      "Fold 5\n",
      "Fold 5 Test Loss: 0.2614\n",
      "Fold 5 Precision: 0.7895\n",
      "Fold 5 Accuracy: 0.6842\n",
      "Fold 5 history Accuracy: 0.8947\n",
      "Fold 5 history Complexity: 9.0000\n",
      "Fold 5 landscape Accuracy: 0.9474\n",
      "Fold 5 landscape Complexity: 1.0000\n",
      "Fold 5 portrait Accuracy: 0.8421\n",
      "Fold 5 portrait Complexity: 6.0000\n",
      "Fold 5 genre Accuracy: 0.4737\n",
      "Fold 5 genre Complexity: 6.0000\n",
      "Fold 5 stilllife Accuracy: 1.0000\n",
      "Fold 5 stilllife Complexity: 3.0000\n",
      "Fold 6\n",
      "Fold 6 Test Loss: 0.2923\n",
      "Fold 6 Precision: 0.7619\n",
      "Fold 6 Accuracy: 0.6316\n",
      "Fold 6 history Accuracy: 0.9474\n",
      "Fold 6 history Complexity: 13.0000\n",
      "Fold 6 landscape Accuracy: 0.7895\n",
      "Fold 6 landscape Complexity: 9.0000\n",
      "Fold 6 portrait Accuracy: 0.8421\n",
      "Fold 6 portrait Complexity: 6.0000\n",
      "Fold 6 genre Accuracy: 0.6842\n",
      "Fold 6 genre Complexity: 17.0000\n",
      "Fold 6 stilllife Accuracy: 0.9474\n",
      "Fold 6 stilllife Complexity: 5.0000\n",
      "Fold 7\n",
      "Fold 7 Test Loss: 0.3282\n",
      "Fold 7 Precision: 0.7500\n",
      "Fold 7 Accuracy: 0.6667\n",
      "Fold 7 history Accuracy: 0.9444\n",
      "Fold 7 history Complexity: 15.0000\n",
      "Fold 7 landscape Accuracy: 0.7222\n",
      "Fold 7 landscape Complexity: 4.0000\n",
      "Fold 7 portrait Accuracy: 0.8889\n",
      "Fold 7 portrait Complexity: 11.0000\n",
      "Fold 7 genre Accuracy: 0.7222\n",
      "Fold 7 genre Complexity: 8.0000\n",
      "Fold 7 stilllife Accuracy: 1.0000\n",
      "Fold 7 stilllife Complexity: 4.0000\n",
      "Fold 8\n",
      "Fold 8 Test Loss: 0.2748\n",
      "Fold 8 Precision: 0.9231\n",
      "Fold 8 Accuracy: 0.6316\n",
      "Fold 8 history Accuracy: 0.8421\n",
      "Fold 8 history Complexity: 12.0000\n",
      "Fold 8 landscape Accuracy: 0.7895\n",
      "Fold 8 landscape Complexity: 1.0000\n",
      "Fold 8 portrait Accuracy: 0.9474\n",
      "Fold 8 portrait Complexity: 9.0000\n",
      "Fold 8 genre Accuracy: 0.5789\n",
      "Fold 8 genre Complexity: 13.0000\n",
      "Fold 8 stilllife Accuracy: 0.9474\n",
      "Fold 8 stilllife Complexity: 3.0000\n",
      "Fold 9\n",
      "Fold 9 Test Loss: 0.2371\n",
      "Fold 9 Precision: 0.8824\n",
      "Fold 9 Accuracy: 0.7778\n",
      "Fold 9 history Accuracy: 0.8333\n",
      "Fold 9 history Complexity: 6.0000\n",
      "Fold 9 landscape Accuracy: 0.8889\n",
      "Fold 9 landscape Complexity: 2.0000\n",
      "Fold 9 portrait Accuracy: 1.0000\n",
      "Fold 9 portrait Complexity: 6.0000\n",
      "Fold 9 genre Accuracy: 0.8889\n",
      "Fold 9 genre Complexity: 8.0000\n",
      "Fold 9 stilllife Accuracy: 0.9444\n",
      "Fold 9 stilllife Complexity: 3.0000\n",
      "Fold 10\n",
      "Fold 10 Test Loss: 0.2656\n",
      "Fold 10 Precision: 0.7895\n",
      "Fold 10 Accuracy: 0.7368\n",
      "Fold 10 history Accuracy: 0.9474\n",
      "Fold 10 history Complexity: 10.0000\n",
      "Fold 10 landscape Accuracy: 0.8421\n",
      "Fold 10 landscape Complexity: 1.0000\n",
      "Fold 10 portrait Accuracy: 0.8421\n",
      "Fold 10 portrait Complexity: 16.0000\n",
      "Fold 10 genre Accuracy: 0.7895\n",
      "Fold 10 genre Complexity: 5.0000\n",
      "Fold 10 stilllife Accuracy: 0.9474\n",
      "Fold 10 stilllife Complexity: 5.0000\n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(df.drop(columns=[df.columns[0],'historypainting', 'landscape', 'portrait','genre_painting','stilllife']).values, dtype=torch.float)\n",
    "y_train = torch.tensor(df[['historypainting', 'landscape', 'portrait','genre_painting','stilllife']].values, dtype=torch.float32)\n",
    "concept_names = df.columns[6:].tolist()\n",
    "class_names = df.columns[1:6].tolist()\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = {\n",
    "    \"loss\": [],\n",
    "    \"precision\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"explanation_accuracy\": [],\n",
    "    \"history Accuracy\": [],\n",
    "    \"history Complexity\": [],\n",
    "    \"landscape Accuracy\": [],\n",
    "    \"landscape Complexity\": [],\n",
    "    \"portrait Accuracy\": [],\n",
    "    \"portrait Complexity\": [],\n",
    "    \"genre Accuracy\": [],\n",
    "    \"genre Complexity\": [],\n",
    "    \"stilllife Accuracy\": [],\n",
    "    \"stilllife Complexity\": [],\n",
    "}\n",
    "\n",
    "trained_models = []\n",
    "model_explanations = []\n",
    "\n",
    "for fold_idx, fold in enumerate(kf.split(x_train)):\n",
    "    print(f\"Fold {fold_idx + 1}\")\n",
    "\n",
    "    final_dataset = pd.DataFrame()\n",
    "    eliminated_rows = pd.DataFrame()\n",
    "\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "\n",
    "        class_rows = df[y_train[:, class_idx].cpu().numpy() == 1] \n",
    "\n",
    "        \n",
    "        sampled_rows = class_rows.sample(frac=0.8, random_state=fold_idx + 42)\n",
    "        eliminated_group = class_rows.drop(index=sampled_rows.index)\n",
    "\n",
    "        \n",
    "        final_dataset = pd.concat([final_dataset, sampled_rows], ignore_index=True)\n",
    "        eliminated_rows = pd.concat([eliminated_rows, eliminated_group], ignore_index=True)\n",
    "\n",
    "    \n",
    "    final_dataset = final_dataset.iloc[index_natsorted(final_dataset[final_dataset.columns[0]])]\n",
    "    final_dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "    eliminated_rows = eliminated_rows.iloc[index_natsorted(eliminated_rows[eliminated_rows.columns[0]])]\n",
    "    eliminated_rows.drop_duplicates(inplace=True)\n",
    "\n",
    "    common_elements = df[df.columns[0]][df[df.columns[0]].isin(final_dataset[final_dataset.columns[0]])].values\n",
    "    original_indices = df.index[df[df.columns[0]].isin(common_elements)].tolist()\n",
    "\n",
    "    train_mask = torch.zeros(len(df), dtype=torch.bool)\n",
    "    train_mask[original_indices] = True\n",
    "\n",
    "    test_mask = ~train_mask\n",
    "\n",
    "    layers = [\n",
    "        te.nn.EntropyLinear(x_train.shape[1], 120, n_classes=5, temperature=0.3),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(120, 60),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(60, 1),\n",
    "    ]\n",
    "    model = torch.nn.Sequential(*layers)\n",
    "\n",
    "    loss_form = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(2000):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x_train).squeeze(-1)\n",
    "        loss = loss_form(y_pred[train_mask], y_train[train_mask].to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model_path = f\"../MODELS/GENRES/model_fold_{fold_idx + 1}.pth\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    trained_models.append(model_path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_test_pred_logits = model(x_train).squeeze(-1)[test_mask]\n",
    "        y_test_pred = (torch.sigmoid(y_test_pred_logits) > 0.5).to(torch.int)\n",
    "\n",
    "        test_loss = loss_form(y_test_pred_logits, y_train[test_mask].to(torch.float))\n",
    "        fold_results[\"loss\"].append(test_loss.item())\n",
    "\n",
    "        global_explanations, local_explanations = entropy.explain_classes(\n",
    "            model,\n",
    "            x_train,\n",
    "            y_train,\n",
    "            train_mask=train_mask,\n",
    "            test_mask=test_mask,\n",
    "            c_threshold=0.1,\n",
    "            y_threshold=0.1,\n",
    "            concept_names=concept_names,\n",
    "            class_names=class_names,\n",
    "            max_minterm_complexity=10,\n",
    "            simplify=True\n",
    "        )\n",
    "\n",
    "        model_explanations.append({\n",
    "            \"global\": global_explanations,\n",
    "        })\n",
    "\n",
    "        precision = precision_score(y_train[test_mask].numpy(), y_test_pred.numpy(), average=\"micro\")\n",
    "        accuracy = accuracy_score(y_train[test_mask].numpy(), y_test_pred.numpy())\n",
    "        fold_results[\"precision\"].append(precision)\n",
    "        fold_results[\"accuracy\"].append(accuracy)\n",
    "        fold_results[\"history Accuracy\"].append(global_explanations['0']['explanation_accuracy'])\n",
    "        fold_results[\"history Complexity\"].append(global_explanations['0']['explanation_complexity'])\n",
    "        fold_results[\"landscape Accuracy\"].append(global_explanations['1']['explanation_accuracy'])\n",
    "        fold_results[\"landscape Complexity\"].append(global_explanations['1']['explanation_complexity'])\n",
    "        fold_results[\"portrait Accuracy\"].append(global_explanations['2']['explanation_accuracy'])\n",
    "        fold_results[\"portrait Complexity\"].append(global_explanations['2']['explanation_complexity'])\n",
    "        fold_results[\"genre Accuracy\"].append(global_explanations['3']['explanation_accuracy'])\n",
    "        fold_results[\"genre Complexity\"].append(global_explanations['3']['explanation_complexity'])\n",
    "        fold_results[\"stilllife Accuracy\"].append(global_explanations['4']['explanation_accuracy'])\n",
    "        fold_results[\"stilllife Complexity\"].append(global_explanations['4']['explanation_complexity'])\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Fold {fold_idx + 1} Test Loss: {test_loss.item():.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} Precision: {precision:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} history Accuracy: {global_explanations['0']['explanation_accuracy']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} history Complexity: {global_explanations['0']['explanation_complexity']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} landscape Accuracy: {global_explanations['1']['explanation_accuracy']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} landscape Complexity: {global_explanations['1']['explanation_complexity']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} portrait Accuracy: {global_explanations['2']['explanation_accuracy']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} portrait Complexity: {global_explanations['2']['explanation_complexity']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} genre Accuracy: {global_explanations['3']['explanation_accuracy']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} genre Complexity: {global_explanations['3']['explanation_complexity']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} stilllife Accuracy: {global_explanations['4']['explanation_accuracy']:.4f}\")\n",
    "        print(f\"Fold {fold_idx + 1} stilllife Complexity: {global_explanations['4']['explanation_complexity']:.4f}\")\n",
    "\n",
    "mean_loss = np.mean(fold_results[\"loss\"])\n",
    "std_loss = np.std(fold_results[\"loss\"])\n",
    "mean_precision = np.mean(fold_results[\"precision\"])\n",
    "mean_accuracy = np.mean(fold_results[\"accuracy\"])\n",
    "mean_his_accuracy = np.mean(fold_results[\"history Accuracy\"])\n",
    "mean_his_complexity = np.mean(fold_results[\"history Complexity\"])\n",
    "mean_land_accuracy = np.mean(fold_results[\"landscape Accuracy\"])\n",
    "mean_land_complexity = np.mean(fold_results[\"landscape Complexity\"])\n",
    "mean_por_accuracy = np.mean(fold_results[\"portrait Accuracy\"])\n",
    "mean_por_complexity = np.mean(fold_results[\"portrait Complexity\"])\n",
    "mean_gen_accuracy = np.mean(fold_results[\"genre Accuracy\"])\n",
    "mean_gen_complexity = np.mean(fold_results[\"genre Complexity\"])\n",
    "mean_still_accuracy = np.mean(fold_results[\"stilllife Accuracy\"])\n",
    "mean_still_complexity = np.mean(fold_results[\"stilllife Complexity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50be1509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "Average Loss: 0.2770 ± 0.0693\n",
      "Average Precision: 0.8128\n",
      "Average Accuracy: 0.6591\n",
      "Average history Accuracy: 0.8751\n",
      "Average history Complexity: 10.5000\n",
      "Average landscape Accuracy: 0.8427\n",
      "Average landscape Complexity: 3.8000\n",
      "Average portrait Accuracy: 0.8980\n",
      "Average portrait Complexity: 7.4000\n",
      "Average genre Accuracy: 0.7208\n",
      "Average genre Complexity: 8.9000\n",
      "Average stilllife Accuracy: 0.9731\n",
      "Average stilllife Complexity: 3.6000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Results:\")\n",
    "print(f\"Average Loss: {mean_loss:.4f} ± {std_loss:.4f}\")\n",
    "print(f\"Average Precision: {mean_precision:.4f}\")\n",
    "print(f\"Average Accuracy: {mean_accuracy:.4f}\")\n",
    "print(f\"Average history Accuracy: {mean_his_accuracy:.4f}\")\n",
    "print(f\"Average history Complexity: {mean_his_complexity:.4f}\")\n",
    "print(f\"Average landscape Accuracy: {mean_land_accuracy:.4f}\")\n",
    "print(f\"Average landscape Complexity: {mean_land_complexity:.4f}\")\n",
    "print(f\"Average portrait Accuracy: {mean_por_accuracy:.4f}\")\n",
    "print(f\"Average portrait Complexity: {mean_por_complexity:.4f}\")\n",
    "print(f\"Average genre Accuracy: {mean_gen_accuracy:.4f}\")\n",
    "print(f\"Average genre Complexity: {mean_gen_complexity:.4f}\")\n",
    "print(f\"Average stilllife Accuracy: {mean_still_accuracy:.4f}\")\n",
    "print(f\"Average stilllife Complexity: {mean_still_complexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d55c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explicaciones de cada modelo:\n",
      "\n",
      "Modelo Fold 1:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(weapons & people_lot) | (jewelry & people_lot & trees_lot) | (people_lot & ~water & ~table & ~jewelry & ~trees_lot) | (~table & ~buildings & ~person & ~people_no & ~trees_lot)', 'name': 'historypainting', 'explanation_accuracy': 0.8421052631578947, 'explanation_complexity': 15}, '1': {'explanation': '(buildings & ~glasses) | (trees_lot & ~people_lot)', 'name': 'landscape', 'explanation_accuracy': 0.9473684210526315, 'explanation_complexity': 4}, '2': {'explanation': '(mountains & jewelry & person) | (person & ~glasses & ~buildings & ~trees_lot)', 'name': 'portrait', 'explanation_accuracy': 0.8947368421052632, 'explanation_complexity': 7}, '3': {'explanation': '(water & people_lot) | (glasses & ~mountains & ~people_no)', 'name': 'genre_painting', 'explanation_accuracy': 0.7368421052631579, 'explanation_complexity': 5}, '4': {'explanation': 'glasses & ~people_few & ~people_group & ~people_lot', 'name': 'stilllife', 'explanation_accuracy': 1.0, 'explanation_complexity': 4}}\n",
      "\n",
      "Modelo Fold 2:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(mountains & weapons) | (people_lot & ~water & ~table & ~jewelry)', 'name': 'historypainting', 'explanation_accuracy': 0.7777777777777778, 'explanation_complexity': 6}, '1': {'explanation': '(buildings & ~glasses) | (trees_lot & ~table & ~people_lot)', 'name': 'landscape', 'explanation_accuracy': 0.7777777777777778, 'explanation_complexity': 5}, '2': {'explanation': 'people_few & trees_no & ~mountains & ~glasses & ~table & ~buildings', 'name': 'portrait', 'explanation_accuracy': 0.9444444444444444, 'explanation_complexity': 6}, '3': {'explanation': '(glasses & ~buildings) | (glasses & ~person) | (water & ~buildings) | (people_few & ~buildings & ~trees_lot) | (~buildings & ~weapons & ~person & ~people_no)', 'name': 'genre_painting', 'explanation_accuracy': 0.7777777777777778, 'explanation_complexity': 13}, '4': {'explanation': 'glasses & people_no', 'name': 'stilllife', 'explanation_accuracy': 1.0, 'explanation_complexity': 2}}\n",
      "\n",
      "Modelo Fold 3:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(mountains & jewelry) | (~water & ~table & ~jewelry & ~buildings & ~person & ~people_no & ~trees_lot)', 'name': 'historypainting', 'explanation_accuracy': 0.8333333333333334, 'explanation_complexity': 9}, '1': {'explanation': 'buildings | (people_no & ~table)', 'name': 'landscape', 'explanation_accuracy': 0.8333333333333334, 'explanation_complexity': 3}, '2': {'explanation': 'person & ~table & ~trees_lot', 'name': 'portrait', 'explanation_accuracy': 0.8333333333333334, 'explanation_complexity': 3}, '3': {'explanation': 'glasses & ~flowers', 'name': 'genre_painting', 'explanation_accuracy': 0.7222222222222222, 'explanation_complexity': 2}, '4': {'explanation': 'glasses & people_no', 'name': 'stilllife', 'explanation_accuracy': 1.0, 'explanation_complexity': 2}}\n",
      "\n",
      "Modelo Fold 4:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(mountains & jewelry & ~person) | (~water & ~table & ~jewelry & ~buildings & ~person & ~people_no & ~trees_lot)', 'name': 'historypainting', 'explanation_accuracy': 0.8888888888888888, 'explanation_complexity': 10}, '1': {'explanation': 'buildings | (~glasses & ~people_few & ~people_lot) | (~jewelry & ~people_lot & ~trees_no & ~trees_few)', 'name': 'landscape', 'explanation_accuracy': 0.8888888888888888, 'explanation_complexity': 8}, '2': {'explanation': 'person & ~glasses & ~buildings & ~trees_lot', 'name': 'portrait', 'explanation_accuracy': 0.9444444444444444, 'explanation_complexity': 4}, '3': {'explanation': '(glasses & ~flowers) | (glasses & trees_lot & ~mountains) | (trees_lot & ~buildings & ~people_few) | (mountains & water & flowers & ~people_few)', 'name': 'genre_painting', 'explanation_accuracy': 0.8333333333333334, 'explanation_complexity': 12}, '4': {'explanation': '~water & ~buildings & ~people_few & ~people_group & ~people_lot', 'name': 'stilllife', 'explanation_accuracy': 0.9444444444444444, 'explanation_complexity': 5}}\n",
      "\n",
      "Modelo Fold 5:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(people_lot & ~water & ~table & ~jewelry) | (jewelry & trees_lot & ~table & ~person & ~people_group)', 'name': 'historypainting', 'explanation_accuracy': 0.8947368421052632, 'explanation_complexity': 9}, '1': {'explanation': 'buildings', 'name': 'landscape', 'explanation_accuracy': 0.9473684210526315, 'explanation_complexity': 1}, '2': {'explanation': 'trees_no & ~glasses & ~table & ~weapons & ~people_no & ~people_lot', 'name': 'portrait', 'explanation_accuracy': 0.8421052631578947, 'explanation_complexity': 6}, '3': {'explanation': '(glasses & ~people_no) | (trees_lot & ~weapons & ~people_no & ~people_few)', 'name': 'genre_painting', 'explanation_accuracy': 0.47368421052631576, 'explanation_complexity': 6}, '4': {'explanation': 'people_no & ~mountains & ~water', 'name': 'stilllife', 'explanation_accuracy': 1.0, 'explanation_complexity': 3}}\n",
      "\n",
      "Modelo Fold 6:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(weapons & ~people_few) | (people_group & ~table & ~jewelry & ~buildings) | (~water & ~table & ~jewelry & ~people_no & ~people_few & ~people_group & ~trees_lot)', 'name': 'historypainting', 'explanation_accuracy': 0.9473684210526315, 'explanation_complexity': 13}, '1': {'explanation': '(buildings & ~mountains & ~people_group) | (flowers & ~people_lot & ~trees_no) | (~jewelry & ~people_lot & ~trees_no)', 'name': 'landscape', 'explanation_accuracy': 0.7894736842105263, 'explanation_complexity': 9}, '2': {'explanation': '(weapons & person) | (person & ~glasses & ~trees_few & ~trees_lot)', 'name': 'portrait', 'explanation_accuracy': 0.8421052631578947, 'explanation_complexity': 6}, '3': {'explanation': 'table | (people_group & ~mountains) | (mountains & people_lot & ~weapons) | (water & people_lot & ~buildings) | (people_lot & ~glasses & ~buildings & ~weapons) | (people_lot & ~jewelry & ~buildings & ~weapons)', 'name': 'genre_painting', 'explanation_accuracy': 0.6842105263157895, 'explanation_complexity': 17}, '4': {'explanation': '~mountains & ~water & ~people_few & ~people_group & ~people_lot', 'name': 'stilllife', 'explanation_accuracy': 0.9473684210526315, 'explanation_complexity': 5}}\n",
      "\n",
      "Modelo Fold 7:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(mountains & jewelry & ~person) | (mountains & ~water & ~buildings & ~person & ~people_no) | (~water & ~table & ~jewelry & ~buildings & ~person & ~people_no & ~trees_lot)', 'name': 'historypainting', 'explanation_accuracy': 0.9444444444444444, 'explanation_complexity': 15}, '1': {'explanation': 'buildings | (~glasses & ~jewelry & ~trees_no)', 'name': 'landscape', 'explanation_accuracy': 0.7222222222222222, 'explanation_complexity': 4}, '2': {'explanation': '(jewelry & person & trees_lot) | (person & ~glasses & ~trees_lot) | (glasses & jewelry & ~person & ~trees_few & ~trees_lot)', 'name': 'portrait', 'explanation_accuracy': 0.8888888888888888, 'explanation_complexity': 11}, '3': {'explanation': '(glasses & people_few) | (glasses & ~buildings) | (~buildings & ~weapons & ~person & ~people_no)', 'name': 'genre_painting', 'explanation_accuracy': 0.7222222222222222, 'explanation_complexity': 8}, '4': {'explanation': 'glasses & ~people_few & ~people_group & ~people_lot', 'name': 'stilllife', 'explanation_accuracy': 1.0, 'explanation_complexity': 4}}\n",
      "\n",
      "Modelo Fold 8:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(weapons & flowers) | (mountains & glasses & ~water) | (glasses & ~flowers & ~people_few) | (mountains & people_few & ~jewelry & ~flowers)', 'name': 'historypainting', 'explanation_accuracy': 0.8421052631578947, 'explanation_complexity': 12}, '1': {'explanation': 'buildings', 'name': 'landscape', 'explanation_accuracy': 0.7894736842105263, 'explanation_complexity': 1}, '2': {'explanation': '(weapons & people_few & trees_lot) | (people_few & ~glasses & ~table & ~buildings & ~weapons & ~trees_lot)', 'name': 'portrait', 'explanation_accuracy': 0.9473684210526315, 'explanation_complexity': 9}, '3': {'explanation': 'table | (glasses & people_few) | (people_lot & ~flowers) | (people_lot & ~weapons & ~trees_few) | (flowers & ~water & ~people_no & ~people_few & ~people_lot)', 'name': 'genre_painting', 'explanation_accuracy': 0.5789473684210527, 'explanation_complexity': 13}, '4': {'explanation': 'people_no & ~water & ~buildings', 'name': 'stilllife', 'explanation_accuracy': 0.9473684210526315, 'explanation_complexity': 3}}\n",
      "\n",
      "Modelo Fold 9:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(mountains & glasses) | (glasses & ~table & ~people_group & ~trees_no)', 'name': 'historypainting', 'explanation_accuracy': 0.8333333333333334, 'explanation_complexity': 6}, '1': {'explanation': 'buildings & ~people_lot', 'name': 'landscape', 'explanation_accuracy': 0.8888888888888888, 'explanation_complexity': 2}, '2': {'explanation': 'people_few & ~mountains & ~water & ~table & ~trees_few & ~trees_lot', 'name': 'portrait', 'explanation_accuracy': 1.0, 'explanation_complexity': 6}, '3': {'explanation': 'table | (people_lot & trees_lot) | (water & ~buildings) | (glasses & people_few & ~buildings)', 'name': 'genre_painting', 'explanation_accuracy': 0.8888888888888888, 'explanation_complexity': 8}, '4': {'explanation': 'people_no & ~mountains & ~buildings', 'name': 'stilllife', 'explanation_accuracy': 0.9444444444444444, 'explanation_complexity': 3}}\n",
      "\n",
      "Modelo Fold 10:\n",
      "Explicaciones Globales:\n",
      "{'0': {'explanation': '(mountains & ~water & ~buildings & ~person & ~people_no) | (people_lot & ~water & ~table & ~jewelry & ~trees_lot)', 'name': 'historypainting', 'explanation_accuracy': 0.9473684210526315, 'explanation_complexity': 10}, '1': {'explanation': 'buildings', 'name': 'landscape', 'explanation_accuracy': 0.8421052631578947, 'explanation_complexity': 1}, '2': {'explanation': '(glasses & buildings & ~people_group) | (weapons & ~people_lot & ~trees_no) | (glasses & people_lot & trees_no & ~table) | (trees_no & ~glasses & ~table & ~weapons & ~people_no & ~people_lot)', 'name': 'portrait', 'explanation_accuracy': 0.8421052631578947, 'explanation_complexity': 16}, '3': {'explanation': '(glasses & ~flowers) | (people_lot & ~buildings & ~weapons)', 'name': 'genre_painting', 'explanation_accuracy': 0.7894736842105263, 'explanation_complexity': 5}, '4': {'explanation': '~mountains & ~water & ~people_few & ~people_group & ~people_lot', 'name': 'stilllife', 'explanation_accuracy': 0.9473684210526315, 'explanation_complexity': 5}}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExplicaciones de cada modelo:\")\n",
    "for i, explanations in enumerate(model_explanations, start=1):\n",
    "    print(f\"\\nModelo Fold {i}:\")\n",
    "    print(\"Explicaciones Globales:\")\n",
    "    print(explanations[\"global\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
